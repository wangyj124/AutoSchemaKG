{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32bc524e",
   "metadata": {},
   "source": [
    "# Networkx ATLAS KG construction and RAG example\n",
    "This notebook demonstrates the full streamlined process of creating a knowledge graph (KG) using the atlas-rag package and performing retrieval-augmented generation (RAG) with our created RAG methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a035b3",
   "metadata": {},
   "source": [
    "## ATLAS KG Construction\n",
    "It is suggested to use local hf model to run the KG construction code, as llm api service provider use optimized, lightweight models to reduce costs, which may sacrifice performance, and hence hard to have guaranteed performance. (for example from fp16 to fp8 etc.)\n",
    "\n",
    "ATLAS KG construction consist of 5 steps:\n",
    "- Triples Json Generation (Base KG Json)\n",
    "- Convert Triples Json to Triples csv\n",
    "- Conceptualize Entity in Triples csv\n",
    "- Merge Concept CSV to Triples CSV\n",
    "- Convert CSV to graphml for networkx to perform rag / to neo4j dumps for Billion KG RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c083856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/httsangaj/miniconda3/envs/atlas-rag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "from atlas_rag.kg_construction.triple_extraction import KnowledgeGraphExtractor\n",
    "from atlas_rag.kg_construction.triple_config import ProcessingConfig\n",
    "from atlas_rag.llm_generator import LLMGenerator\n",
    "from openai import OpenAI\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from transformers import pipeline\n",
    "from configparser import ConfigParser\n",
    "# Load OpenRouter API key from config file\n",
    "config = ConfigParser()\n",
    "config.read('config.ini')\n",
    "# model_name = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "# connection = AIProjectClient(\n",
    "#     endpoint=config[\"urls\"][\"AZURE_URL\"],\n",
    "#     credential=DefaultAzureCredential(),\n",
    "# )\n",
    "# client = connection.inference.get_azure_openai_client(api_version=\"2024-12-01-preview\")\n",
    "client = OpenAI(base_url=\"http://0.0.0.0:8129/v1\", api_key=\"EMPTY\")\n",
    "triple_generator = LLMGenerator(client=client, model_name=\"Qwen/Qwen2.5-7B-Instruct\")\n",
    "\n",
    "# model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "# model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "# client = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model_name,\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "filename_pattern = 'test_data'\n",
    "output_directory = f'benchmark_data'\n",
    "# triple_generator = LLMGenerator(client, model_name=model_name)\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37353f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom kg extraction prompt:\n",
      "{'en': {'system': 'You are a helpful assistant', 'triple_extraction': 'You are an expert knowledge graph constructor. Your task is to extract factual information from the provided text and represent it as a list of knowledge graph triples.\\nEach triple should be a JSON object with three keys:\\n1.  `subject`: The main entity, concept, event, or attribute of the triple.\\n2.  `relation`: The relationship between the subject and the object.\\n3.  `object`: The entity, concept, value, event, or attribute that the subject has a relationship with.\\nConstraints:\\n- Extract all possible and relevant triples.\\n- The `subject` and `object` can be specific entities (e.g., \"Radio City\", \"Football in Albania\", \"Echosmith\") or specific values (e.g., \"3 July 2001\", \"1,310,696\").\\n- The `relation` should be a concise, descriptive phrase or verb that accurately describes the relationship (e.g., \"founded by\", \"started on\", \"is a\", \"has circulation of\").\\n- Ensure the triples are self-contained and logically sound.\\n- If no triples can be extracted from the text, return an empty JSON list: `[]`.\\n- Do not include any text other than the JSON output.'}}\n",
      "Using custom kg extraction schema:\n",
      "{'triple_extraction': {'type': 'array', 'items': {'type': 'object', 'properties': {'subject': {'type': 'string'}, 'relation': {'type': 'string'}, 'object': {'type': 'string'}}, 'required': ['subject', 'relation', 'object']}}}\n",
      "{'type': 'array', 'items': {'type': 'object', 'properties': {'subject': {'type': 'string'}, 'relation': {'type': 'string'}, 'object': {'type': 'string'}}, 'required': ['subject', 'relation', 'object']}}\n"
     ]
    }
   ],
   "source": [
    "kg_extraction_config = ProcessingConfig(\n",
    "      model_path=model_name,\n",
    "      data_directory=f'benchmark_data/{filename_pattern}',\n",
    "      filename_pattern=filename_pattern,\n",
    "      batch_size_triple=16,\n",
    "      batch_size_concept=16,\n",
    "      output_directory=f\"{output_directory}\",\n",
    "      max_new_tokens=2048,\n",
    "      max_workers=3,\n",
    "      remove_doc_spaces=True, # For removing duplicated spaces in the document text\n",
    "      include_concept=False, # Whether to include concept nodes and edges in the knowledge graph\n",
    "      triple_extraction_prompt_path='example/example_scripts/custom_extraction/custom_benchmark/custom_prompt.json',\n",
    "      triple_extraction_schema_path='example/example_scripts/custom_extraction/custom_benchmark/custom_schema.json',\n",
    "      record=True, # Whether to record the results in a JSON file\n",
    ")\n",
    "kg_extractor = KnowledgeGraphExtractor(model=triple_generator, config=kg_extraction_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c248a3",
   "metadata": {},
   "source": [
    "### Triples Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c10bffac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found data files: ['test_data.json']\n",
      "Processing shard 1/1 (texts 0-0 of 1, 1 documents)\n",
      "Generated 1 chunks for shard 1/1\n",
      "Model: Qwen/Qwen2.5-7B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1 batches (16 chunks)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# construct entity&event graph\n",
    "kg_extractor.run_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c8f043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from the json files\n",
      "Number of files:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 880.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file for file ids:  Qwen_Qwen2.5-7B-Instruct_test_data_output_20250810150302_1_in_1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert Triples Json to CSV\n",
    "kg_extractor.convert_json_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "335211ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_batches 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shard_0:   0%|          | 0/3 [00:00<?, ?it/s]2025-08-10 14:57:49,132 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:49,156 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:49,179 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:49,342 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:49,343 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:49,363 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:49,504 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:49,527 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:49,552 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:49,692 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:49,715 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:49,765 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:49,858 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:49,929 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:49,929 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:50,012 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:50,014 - INFO - Usage log: Node for departure, completion_usage: {'completion_tokens': 6, 'prompt_tokens': 402, 'total_tokens': 408, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.16327786445617676}\n",
      "2025-08-10 14:57:50,016 - INFO - Usage log: Node with a strained smile, completion_usage: {'completion_tokens': 7, 'prompt_tokens': 399, 'total_tokens': 406, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.2081594467163086}\n",
      "2025-08-10 14:57:50,017 - INFO - Usage log: Node Sam Rivera, completion_usage: {'completion_tokens': 6, 'prompt_tokens': 405, 'total_tokens': 411, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.18347549438476562}\n",
      "2025-08-10 14:57:50,017 - INFO - Usage log: Node briefing room, completion_usage: {'completion_tokens': 8, 'prompt_tokens': 401, 'total_tokens': 409, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.2123873233795166}\n",
      "2025-08-10 14:57:50,018 - INFO - Usage log: Node Paranormal Military Squad's elite, completion_usage: {'completion_tokens': 8, 'prompt_tokens': 401, 'total_tokens': 409, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.20557045936584473}\n",
      "2025-08-10 14:57:50,019 - INFO - Usage log: Node resolve, completion_usage: {'completion_tokens': 6, 'prompt_tokens': 403, 'total_tokens': 409, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.1625075340270996}\n",
      "2025-08-10 14:57:50,020 - INFO - Usage log: Node Jordan Hayes, completion_usage: {'completion_tokens': 6, 'prompt_tokens': 401, 'total_tokens': 407, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.16160011291503906}\n",
      "2025-08-10 14:57:50,021 - INFO - Usage log: Node if Agent Alex Mercer was having second thoughts, completion_usage: {'completion_tokens': 8, 'prompt_tokens': 402, 'total_tokens': 410, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.20620322227478027}\n",
      "2025-08-10 14:57:50,021 - INFO - Usage log: Node their impending odyssey into Operation: Dulce, completion_usage: {'completion_tokens': 6, 'prompt_tokens': 403, 'total_tokens': 409, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.16378402709960938}\n",
      "2025-08-10 14:57:50,022 - INFO - Usage log: Node with the words 'counter-productive', completion_usage: {'completion_tokens': 7, 'prompt_tokens': 403, 'total_tokens': 410, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.18829751014709473}\n",
      "2025-08-10 14:57:50,023 - INFO - Usage log: Node after Taylor Cruz's reprimand, completion_usage: {'completion_tokens': 7, 'prompt_tokens': 406, 'total_tokens': 413, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.1880354881286621}\n",
      "2025-08-10 14:57:50,024 - INFO - Usage log: Node as they prepared for departure, completion_usage: {'completion_tokens': 8, 'prompt_tokens': 403, 'total_tokens': 411, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.21364498138427734}\n",
      "2025-08-10 14:57:50,025 - INFO - Usage log: Node to Agent Alex Mercer, completion_usage: {'completion_tokens': 6, 'prompt_tokens': 401, 'total_tokens': 407, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.16596055030822754}\n",
      "2025-08-10 14:57:50,026 - INFO - Usage log: Node ever so slightly, completion_usage: {'completion_tokens': 8, 'prompt_tokens': 399, 'total_tokens': 407, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.21551299095153809}\n",
      "2025-08-10 14:57:50,026 - INFO - Usage log: Node with Agent Taylor Cruz, completion_usage: {'completion_tokens': 6, 'prompt_tokens': 399, 'total_tokens': 405, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.1633291244506836}\n",
      "2025-08-10 14:57:50,027 - INFO - Usage log: Node for the two of them, completion_usage: {'completion_tokens': 6, 'prompt_tokens': 405, 'total_tokens': 411, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.15354061126708984}\n",
      "Shard_0:  33%|███▎      | 1/3 [00:01<00:02,  1.06s/it]2025-08-10 14:57:50,255 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:50,256 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:50,275 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:50,417 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:50,417 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:50,458 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:50,460 - INFO - Usage log: Node Agent Alex Mercer, completion_usage: {'completion_tokens': 8, 'prompt_tokens': 399, 'total_tokens': 407, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.22786402702331543}\n",
      "2025-08-10 14:57:50,461 - INFO - Usage log: Node projectors, completion_usage: {'completion_tokens': 10, 'prompt_tokens': 403, 'total_tokens': 413, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.24458694458007812}\n",
      "2025-08-10 14:57:50,462 - INFO - Usage log: Node about Agent Alex Mercer's struggle, completion_usage: {'completion_tokens': 8, 'prompt_tokens': 404, 'total_tokens': 412, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.2265322208404541}\n",
      "2025-08-10 14:57:50,463 - INFO - Usage log: Node the projectors, completion_usage: {'completion_tokens': 6, 'prompt_tokens': 398, 'total_tokens': 404, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.16108441352844238}\n",
      "2025-08-10 14:57:50,464 - INFO - Usage log: Node Taylor Cruz, completion_usage: {'completion_tokens': 6, 'prompt_tokens': 403, 'total_tokens': 409, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.1590867042541504}\n",
      "2025-08-10 14:57:50,465 - INFO - Usage log: Node unfailingly, completion_usage: {'completion_tokens': 7, 'prompt_tokens': 400, 'total_tokens': 407, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.18223118782043457}\n",
      "Shard_0:  67%|██████▋   | 2/3 [00:01<00:00,  1.44it/s]2025-08-10 14:57:50,665 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:50,687 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:50,712 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:50,828 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:50,875 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:50,922 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:50,992 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:51,106 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:51,198 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:51,290 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:51,338 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:51,497 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:51,520 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:51,567 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:51,713 - INFO - HTTP Request: POST http://0.0.0.0:8129/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-10 14:57:51,715 - INFO - Usage log: Node tilted their head, completion_usage: {'completion_tokens': 8, 'prompt_tokens': 274, 'total_tokens': 282, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.19976162910461426}\n",
      "2025-08-10 14:57:51,716 - INFO - Usage log: Node offered a supportive nod, completion_usage: {'completion_tokens': 8, 'prompt_tokens': 275, 'total_tokens': 283, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.21835613250732422}\n",
      "2025-08-10 14:57:51,716 - INFO - Usage log: Node agreed, completion_usage: {'completion_tokens': 9, 'prompt_tokens': 272, 'total_tokens': 281, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.24070119857788086}\n",
      "2025-08-10 14:57:51,717 - INFO - Usage log: Node outlining, completion_usage: {'completion_tokens': 6, 'prompt_tokens': 272, 'total_tokens': 278, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.1629652976989746}\n",
      "2025-08-10 14:57:51,717 - INFO - Usage log: Node scanned, completion_usage: {'completion_tokens': 9, 'prompt_tokens': 272, 'total_tokens': 281, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.23455119132995605}\n",
      "2025-08-10 14:57:51,718 - INFO - Usage log: Node enormous to, completion_usage: {'completion_tokens': 6, 'prompt_tokens': 273, 'total_tokens': 279, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.16263270378112793}\n",
      "2025-08-10 14:57:51,718 - INFO - Usage log: Node asked, completion_usage: {'completion_tokens': 6, 'prompt_tokens': 272, 'total_tokens': 278, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.16267132759094238}\n",
      "2025-08-10 14:57:51,719 - INFO - Usage log: Node reprimanded, completion_usage: {'completion_tokens': 9, 'prompt_tokens': 274, 'total_tokens': 283, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.23096084594726562}\n",
      "2025-08-10 14:57:51,719 - INFO - Usage log: Node revealed a spark of understanding, completion_usage: {'completion_tokens': 11, 'prompt_tokens': 276, 'total_tokens': 287, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.27586984634399414}\n",
      "2025-08-10 14:57:51,720 - INFO - Usage log: Node combed through the last transmission logs, completion_usage: {'completion_tokens': 12, 'prompt_tokens': 278, 'total_tokens': 290, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.2985377311706543}\n",
      "2025-08-10 14:57:51,720 - INFO - Usage log: Node took form within Agent Alex Mercer, completion_usage: {'completion_tokens': 9, 'prompt_tokens': 277, 'total_tokens': 286, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.23150014877319336}\n",
      "2025-08-10 14:57:51,721 - INFO - Usage log: Node straightened in his seat, completion_usage: {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.2989840507507324}\n",
      "2025-08-10 14:57:51,724 - INFO - Usage log: Node determined on paper, completion_usage: {'completion_tokens': 11, 'prompt_tokens': 274, 'total_tokens': 285, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.2763478755950928}\n",
      "2025-08-10 14:57:51,724 - INFO - Usage log: Node began to collect his binders, completion_usage: {'completion_tokens': 7, 'prompt_tokens': 277, 'total_tokens': 284, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.18216967582702637}\n",
      "2025-08-10 14:57:51,725 - INFO - Usage log: Node responded, completion_usage: {'completion_tokens': 9, 'prompt_tokens': 272, 'total_tokens': 281, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'time': 0.21616435050964355}\n",
      "Shard_0: 100%|██████████| 3/3 [00:02<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique conceptualized nodes: 113\n",
      "Number of unique conceptualized events: 0\n",
      "Number of unique conceptualized entities: 64\n",
      "Number of unique conceptualized relations: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Concept Generation\n",
    "kg_extractor.generate_concept_csv_temp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5823e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [00:00, 46422.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading concepts done.\n",
      "Relation to concepts: 15\n",
      "Node to concepts: 22\n",
      "Processing triple nodes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:00, 34302.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing concept nodes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 222953.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing triple edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:00, 72232.56it/s]\n"
     ]
    }
   ],
   "source": [
    "kg_extractor.create_concept_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84480f15",
   "metadata": {},
   "source": [
    "# Choice 1: Convert to graphml for networkx rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "348f651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert csv to graphml for networkx\n",
    "kg_extractor.convert_to_graphml()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8f197d",
   "metadata": {},
   "source": [
    "## ATLAS Multihop QA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b957c1",
   "metadata": {},
   "source": [
    "In order to perform RAG, one need to first create embeddings & faiss index for constructed KG\n",
    "\n",
    "[There maybe performance difference in using AutoModel and Sentence Transformer for NV-Ebmed-v2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c5d1aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from atlas_rag.vectorstore.embedding_model import NvEmbed, SentenceEmbedding\n",
    "from transformers import AutoModel\n",
    "# Load the SentenceTransformer model\n",
    "encoder_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "sentence_model = SentenceTransformer(encoder_model_name, trust_remote_code=True, model_kwargs={'device_map': \"auto\"})\n",
    "sentence_encoder = SentenceEmbedding(sentence_model)\n",
    "# sentence_model.max_seq_length = 32768\n",
    "# sentence_model.tokenizer.padding_side=\"right\"\n",
    "# sentence_model = AutoModel.from_pretrained(encoder_model_name, trust_remote_code=True, device_map=\"auto\")\n",
    "# sentence_encoder = NvEmbed(sentence_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a106e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized LLMGenerator with inference_type='api', backend='openai'\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from atlas_rag.llm_generator import LLMGenerator\n",
    "from configparser import ConfigParser\n",
    "# Load OpenRouter API key from config file\n",
    "config = ConfigParser()\n",
    "config.read('config.ini')\n",
    "# reader_model_name = \"meta-llama/llama-3.3-70b-instruct\"\n",
    "reader_model_name = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "client = OpenAI(\n",
    "  # base_url=\"https://openrouter.ai/api/v1\",\n",
    "  # api_key=config['settings']['OPENROUTER_API_KEY'],\n",
    "  base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    "  api_key=config['settings']['DEEPINFRA_API_KEY'],\n",
    ")\n",
    "llm_generator = LLMGenerator(client=client, model_name=reader_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07ba40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using encoder model: all-MiniLM-L6-v2\n",
      "Loading graph from import/CICGPC_Glazing_ver1.0a/kg_graphml/CICGPC_Glazing_ver1.0a_graph.graphml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1118/1118 [00:00<00:00, 1113302.91it/s]\n",
      "100%|██████████| 1118/1118 [00:00<00:00, 705784.45it/s]\n",
      "3304it [00:00, 1412782.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text embeddings already computed.\n",
      "Graph embeddings already computed\n",
      "Node and edge embeddings already computed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from atlas_rag.vectorstore import create_embeddings_and_index\n",
    "keyword = 'CICGPC_Glazing_ver1.0a'\n",
    "working_directory = f'import/{keyword}'\n",
    "data = create_embeddings_and_index(\n",
    "    sentence_encoder=sentence_encoder,\n",
    "    model_name = encoder_model_name,\n",
    "    working_directory=working_directory,\n",
    "    keyword=keyword,\n",
    "    include_concept=True,\n",
    "    include_events=True,\n",
    "    normalize_embeddings= True,\n",
    "    text_batch_size=64,\n",
    "    node_and_edge_batch_size=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f86997e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize desired RAG method for benchmarking\n",
    "from atlas_rag.retriever import HippoRAG2Retriever\n",
    "from atlas_rag import setup_logger\n",
    "\n",
    "hipporag2_retriever = HippoRAG2Retriever(\n",
    "    llm_generator=llm_generator,\n",
    "    sentence_encoder=sentence_encoder,\n",
    "    data = data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "179b3850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved content: ['he limits below (Table 1). Bonus points will be awarded if the U-value of the product reaches the standard in Table 1. | U-value (W/m2K) | single glazing | double or tripled glazing | Points | |-----------------|----------------|---------------------------|--------| | | ≤ 5.8 | ≤ 3.30 | | | ≤ 3.7 | ≤ 2.30 | +5<br>(bonus) | | *Table 1: Limits of U-value for single, double or tripled glazing products* #### Verification Laboratory test report(s) on the U-value of the glazing product. The U-value should be measured according to the applicable ISO 8990 or EN-ISO 12567 standard. Alternatively, the U-value can be calculated according to the standard EN673 (Glazing) and EN ISO 10077 (Frame / Casement). ### <span id=\"page-10-2\"></span>*4.2.2 Shading Coefficient* #### 15 Basic + 5 / 10 Bonus Points (Core Criterion) Shading coefficient (SC) and solar heat gain coefficient **(**SHGC) can portray how well a product blocks heat caused by sunlight. The lower the glazing\\'s SHGC, the less solar heat it transmits into a building. These two coefficients can be converted according to the equation below: *SHGC* = *SC* × 0.87 SC or SHGC of the glazing products shall meet the limits below (Table 2). Bonus points will be awarded if SC or SHGC of the product the standard in Table 2. # **Copyright © 2020 Construction Industry Council** *Table 2: Limits of shading coefficients and corresponding solar heat gain coefficient for glazing products* | | 15 [basic] | +5 (bonus) | +10 (bonus) | |-----------------------------|------------|------------|-------------| | Shading coefficient | ≤ 0.90 | ≤ 0.60 | ≤ 0.40 | | Solar heat gain coefficient | ≤ 0.78 | ≤ 0.52 | ≤ 0.35 | #### <span id=\"page-11-0\"></span>*4.2.3 Visible Light Transmittance* #### 10 Basic + 5 Bonus Points (Core Criterion) Visible light transmittance (VLT) is an optical property which indicates the amount of visible light transmitted through the glass. VLT of the glazing product shall be greater than 50%. FIVE bonus points will be awarded if VLT of the product shall be reach 70%. #### <span id=\"page-11-1\"></span>*4.2.4 External Reflectance* #### 10 Points (Core Criterion) External reflectance measures how much light from external source is reflected by the glazing product. Limiting external reflectance on buildings are intended to minimise hindrances caused by sunlight. The external reflectance of glazing product shall be less than 20%. #### Verification (for Criteria 4.2.2– 4.2.4) Laboratory test report(s) on the SC, SHGC, external reflectance and VLT of the glazing product. Spectral measurements shall comply with ASTM E903 and the SHGC and VLT should be measured in accordance with the EN 410 or ISO 9050 standard. #### <span id=\"page-11-2\"></span>*4.2.5 Energy Management in Manufacturing* #### 5 Points (Core Criterion) The Applicant shall have effective energy management policies and procedures and /', 'e label of the CIC Green Product Certification of the Construction Industry Council *CIC:* Construction Industry Council *CNAS:* China National Accreditation Service for Conformity Assessment *Double or triple glazing:* Windows that have two layers of glass to keep a building warm or to reduce noise from outside *External reflectance:* The percentage of daylight reflected from any external surface of any window, door, wall or roof of a building *Glazing:* A part of the façade or window which is made of [glass,](http://en.wikipedia.org/wiki/Glass) and it could be transparent or semi-transparent to solar radiation *HKAS:* Hong Kong Accreditation Service *HKGBC:* The Hong Kong Green Building Council Limited *HOKLAS:* The Hong Kong Laboratory Accreditation Scheme *IARC:* International Agency for Research on Cancer *ISO:* International Organisation for Standardisation *MSDS:* Material Safety Data Sheet. To qualify as suitable, the MSDS and information therein must not be more than 5-years old *Shading coefficient (SC):* The ratio of the rate of solar heat gain through a specific unit assembly of glass to the solar heat gain through a 3mm single lite of clear glass in the same #### 2 **Copyright © 2020 Construction Industry Council** situation *Single glazing:* Windows that are made up of a single sheet of glass *Solar heat gain coefficient (SHGC):* The ratio of solar heat gain entering the space through the glazing product to the incident solar radiation which is expressed as a value between 0 and 1 *Standard single glazing:* Standard single glazing refers to 3mm clear float glass *Third-party:* An entity without any financial interest or stake in the sales of the product or service being evaluated or other conflict of interest *U-value:* Overall heat transferred due to conduction, convection and long wave infra-red radiation, on average in unites of time per unit area (m<sup>2</sup> ) of the entire glazing product when the temperature difference between the indoor and outdoor sides of the product is one 1 degree under the Kelvin temperature scale. Expressed here in units of W/m<sup>2</sup>K *Visible light transmittance (VLT):* The fraction of total visible light that transmits from the glazing\\'s outdoor side to the indoor side, weighted by the sensitivity of human eye (wavelength range of 0.38 to 0.78 μm) # <span id=\"page-7-0\"></span>**4. EVALUATION CRITERIA** A product to be assessed should meet all the minimum requirements of the \"Core Criteria\" in order to be awarded a \"Green\" (i.e. a \"pass\" grade) Label under the Scheme. Bonus points may be awarded if the product meets the \"Non-core Criteria\" and a \"Bronze\", \"Silver\", \"Gold\" or \"Platinum\" Label will be awarded according to the total points accumulated (see Section 5 for details). All submissions and documentations shall be endorsed by the Chief Executive Officer or other authorised', 'as harmful, toxic or very toxic in accordance with European Union Directive 2001/59/EC The following requirements are applicable to tinted glazing product only:<br>Product shall not contain toxic heavy metals, or ingredients containing heavy metals, including lead (Pb), cadmium (Cd), mercury (Hg), chromium (Cr), arsenic (As), selenium (Se), antimony (Sb), and cobalt (Co). The following requirements are applicable to double/triple glazing product only:<br>Product shall not contain chlorinated / brominated paraffins Filler gases used in the insulating units: $≤ 5$ in $GWP_{100}$ | Laboratory test report(s), MSDS, self-declaration letter and production documentation | +10 | 4.3.1 (page 8) | |----------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------|-----|----------------| | | | Subtotal: | +30 | | | Section | Subsection | Title and Page Number | |---------|------------|-----------------------------------------------| | 1. | | INTRODUCTION<br>1 | | | 1.1 | PURPOSE<br>1 | | | 1.2 | BACKGROUND<br>1 | | 2. | | SCOPE<br>1 | | 3. | | DEFINITIONS<br>2 | | 4. | | EVALUATION CRITERIA<br>3 | | | 4.1 | GENERAL REQUIREMENTS<br>3 | | | | 4.1.1 Serviceability<br>3 | | | | 4.1.2 Environmental Management System<br>4 | | | | 4.1.3 Product Information<br>4 | | | | 4.1.4 Packaging Requirements<br>5 | | | | 4.1.5 Extra Environmental Features<br>5 | | | 4.2 | RESOURCE CONSUMPTION<br>6 | | | | 4.2.1 Thermal Insulation Performance<br>6 | | | | 4.2.2 Shading Coefficient<br>6 | | | | 4.2.3 Visible Light Transmittance<br>7 | | | | 4.2.4 External Reflectance<br>7 | | | | 4.2.5 Energy Management in Manufacturing<br>7 | | | 4.3 | HUMAN TOXICITY AND ECOSYSTEM IMPACT<br>8 | | | | 4.3.1 Hazardous Substances<br>8 | | 5. | | SCORING AND GRADING<br>9 | ## <span id=\"page-5-0\"></span>**1. INTRODUCTION** <span id=\"page-5-1\"></span> ## **1.1 PURPOSE** The CIC Green Product Certification *(formerly known as HKGBC Green Product Accreditation and Standards [HK G-PASS])* (herein']\n"
     ]
    }
   ],
   "source": [
    "# perform retrieval\n",
    "content, sorted_context_ids = hipporag2_retriever.retrieve(\"How is the U-value relevant to thermal insulation performance in glazing products?\", topN=3)\n",
    "print(f\"Retrieved content: {content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5b515ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To determine the relevance of the U-value to thermal insulation performance in glazing products, we need to understand what the U-value represents and how it relates to thermal insulation. The U-value, or thermal transmittance, is a measure of the rate of heat transfer through a material or an assembly of materials, such as glazing. It is expressed in units of watts per square meter per degree Kelvin (W/m²K). A lower U-value indicates better thermal insulation performance, as less heat is transferred through the material.\\n\\nIn the context of glazing products, the U-value is crucial because it directly affects the energy efficiency and thermal comfort of buildings. Glazing with a low U-value reduces heat loss in winter and heat gain in summer, thereby minimizing the need for heating and cooling. This not only saves energy but also reduces the environmental impact associated with energy consumption.\\n\\nThe provided text outlines specific U-value limits for single, double, and triple glazing products to qualify for the CIC Green Product Certification. For instance, to qualify for bonus points, the U-value of double or triple glazing products should be ≤ 2.30 W/m²K, indicating a high level of thermal insulation performance.\\n\\nTherefore, the U-value is highly relevant to the thermal insulation performance of glazing products, as it quantifies their ability to reduce heat transfer and improve energy efficiency in buildings.\\n\\nAnswer: Thermal Insulation Performance Indicator'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start benchmarking\n",
    "sorted_context = \"\\n\".join(content)\n",
    "llm_generator.generate_with_context(\"How is the U-value relevant to thermal insulation performance in glazing products?\", sorted_context, max_new_tokens=2048, temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5100a428",
   "metadata": {},
   "source": [
    "# Choice 2: Convert to neo4j dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d114689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from atlas_rag.vectorstore.embedding_model import SentenceEmbedding\n",
    "# use sentence embedding if you want to use sentence transformer\n",
    "# use NvEmbed if you want to use NvEmbed-v2 model\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sentence_encoder = SentenceEmbedding(sentence_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a4e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add numeric id to the csv so that we can use vector indices\n",
    "kg_extractor.add_numeric_id()\n",
    "\n",
    "# compute embedding\n",
    "kg_extractor.compute_kg_embedding(sentence_encoder) # default encoder_model_name=\"all-MiniLM-L12-v2\", only compute all embeddings except any concept related embeddings\n",
    "# kg_extractor.compute_embedding(encoder_model_name=\"all-MiniLM-L12-v2\")\n",
    "# kg_extractor.compute_embedding(encoder_model_name=\"nvidia/NV-Embed-v2\")\n",
    "\n",
    "# create faiss index\n",
    "kg_extractor.create_faiss_index(faiss_gpu=False) # default index_type=\"HNSW,Flat\", other options: \"IVF65536_HNSW32,Flat\" for large KG\n",
    "# kg_extractor.create_faiss_index(index_type=\"HNSW,Flat\")\n",
    "# kg_extractor.create_faiss_index(index_type=\"IVF65536_HNSW32,Flat\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a89d518",
   "metadata": {},
   "source": [
    "## Install Neo4j Server\n",
    "\n",
    "Go to the AutoschemaKG/neo4j_scripts directory\n",
    "\n",
    "```sh get_neo4j_demo.sh```\n",
    "\n",
    "Then there a neo4j server is install in the directory: neo4j-server-dulce\n",
    "\n",
    "Start the newly instealled empty Neo4j server for testing\n",
    "\n",
    "```sh start_neo4j_demo.sh```\n",
    "\n",
    "\n",
    "\n",
    "## Config Neo4j Server\n",
    "\n",
    "Stop the server first before config and import data\n",
    "\n",
    "```sh stop_neo4j_demo.sh```\n",
    "\n",
    "\n",
    "Copy the ```AutoschemaKG/neo4j_scripts/neo4j.conf``` file to the conf directory of the Neo4j server (```neo4j-server-dulce/conf```). Then, update the following settings as needed: 1.Set dbms.default_database to the desired dataset name, such as ```wiki-csv-json-text```, ```pes2o-csv-json-text```, or ```cc-csv-json-text```. In this case we make it ```dulce-csv-json-text``` 2.Configure the Bolt, HTTP, and HTTPS connectors according to your requirements.\n",
    "\n",
    "I have set up the config port to some random ports to avoid port conflicts in ```neo4j-server-dulce/conf/neo4j.conf``` .\n",
    "\n",
    " \n",
    "``` \n",
    "# Bolt connector\n",
    "server.bolt.enabled=true\n",
    "#server.bolt.tls_level=DISABLED\n",
    "server.bolt.listen_address=0.0.0.0:8612\n",
    "server.bolt.advertised_address=:8612\n",
    "\n",
    "# HTTP Connector. There can be zero or one HTTP connectors.\n",
    "server.http.enabled=true\n",
    "server.http.listen_address=0.0.0.0:7612\n",
    "server.http.advertised_address=:7612\n",
    "\n",
    "# HTTPS Connector. There can be zero or one HTTPS connectors.\n",
    "server.https.enabled=false\n",
    "server.https.listen_address=0.0.0.0:7781\n",
    "server.https.advertised_address=:7781\n",
    "```\n",
    "\n",
    "\n",
    "## Import Data\n",
    "We use the admin import method to import data, which is the fastest way. Other methods are too slow for large graphs.\n",
    "\n",
    "\n",
    "## Load the CSV files into Neo4j\n",
    "\n",
    "We try to import data from previously constructed csv files with numeric ids. All the csv files are in ```import/Dulce```. \n",
    "In total six csv files for the nodes and edges of triples, text chunks, and concepts. \n",
    "\n",
    "``` shell\n",
    "./neo4j-server-dulce/bin/neo4j-admin database import full dulce-csv-json-text \\\n",
    "    --nodes ./import/Dulce/triples_csv/triple_nodes_Dulce_from_json_without_emb_with_numeric_id.csv \\\n",
    "    --nodes ./import/Dulce/triples_csv/text_nodes_Dulce_from_json_with_numeric_id.csv \\\n",
    "    --nodes ./import/Dulce/concept_csv/concept_nodes_Dulce_from_json_with_concept.csv \\\n",
    "    --relationships ./import/Dulce/triples_csv/triple_edges_Dulce_from_json_without_emb_with_numeric_id.csv \\\n",
    "    --relationships ./import/Dulce/triples_csv/text_edges_Dulce_from_json.csv \\\n",
    "    --relationships ./import/Dulce/concept_csv/concept_edges_Dulce_from_json_with_concept.csv  \\\n",
    "    --overwrite-destination \\\n",
    "    --multiline-fields=true \\\n",
    "    --id-type=string \\\n",
    "    --verbose --skip-bad-relationships=true\n",
    "```\n",
    "\n",
    "When this is finished, you can see the following notifications\n",
    "\n",
    "```shell\n",
    "IMPORT DONE in 2s 475ms. \n",
    "Imported:\n",
    "  1183 nodes\n",
    "  2519 relationships\n",
    "  6743 properties\n",
    "Peak memory usage: 1.032GiB\n",
    "```\n",
    "\n",
    "Then you can start host it by running in ```./neo4j_scripts```\n",
    "\n",
    "```sh start_neo4j_demo.sh```\n",
    "\n",
    "When you see the following line, then it is working well.\n",
    "\n",
    "\n",
    "```Started neo4j (pid:742490). It is available at http://0.0.0.0:7612```\n",
    "\n",
    "\n",
    "\n",
    "If you want to use the python driver to run neo4j, you need to use port 8612. You can access http://0.0.0.0:7612 in browser as well to use the neo4j GUI. \n",
    "\n",
    "The default user is ```neo4j``` with password ```admin2024```. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a5e827",
   "metadata": {},
   "source": [
    "## ATLAS Billion Level RAG\n",
    "The LargeKGRetriever is designed to perform retrieval on a billion-level graph. \n",
    "\n",
    "There is a trade-off between retrieval performance and speed; this serves as a proof of concept for a billion-level knowledge graph.\n",
    "\n",
    "After successfully hosting the Neo4j database, you can run the provided Python script to host the RAG API:\n",
    "```shell\n",
    "python neo4j_api_host/atlas_api_demo.py \n",
    "```\n",
    "\n",
    "During the first startup of the API, it will create the necessary indexes and projection graphs in the Neo4j database for faster queries and computations. The time required for this process may vary depending on the size of the database. You can monitor the creation of these items in http://localhost:7612 by using the following commands:\n",
    "\n",
    "To view the projected graphs:\n",
    "```cypher\n",
    "CALL gds.graph.list()\n",
    "```\n",
    "To view the indexes:\n",
    "```cypher\n",
    "SHOW INDEXES\n",
    "```\n",
    "\n",
    "The projected graph will be deleted after the database is shut down, while the indexes will not be removed.\n",
    "\n",
    "After you saw: \\\n",
    "Index NodeNumericIDIndex created in 0.09 seconds \\\n",
    "Index TextNumericIDIndex created in 0.11 seconds \\\n",
    "Index EntityEventEdgeNumericIDIndex created in 0.02 seconds \\\n",
    "Projection graph largekgrag_graph created in 5.42 seconds \n",
    "\n",
    "You can perform rag as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a02dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "base_url =\"http://0.0.0.0:10085/v1/\"\n",
    "client = OpenAI(api_key=\"EMPTY\", base_url=base_url)\n",
    "\n",
    "# knowledge graph en_simple_wiki_v0\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that answers questions based on the knowledge graph.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Question: Who is Alex Mercer?\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama\",\n",
    "    messages=message,\n",
    "    max_tokens=2048,\n",
    "    temperature=0.5\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5b5d70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
